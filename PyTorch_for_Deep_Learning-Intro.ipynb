{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-andorra",
   "metadata": {},
   "source": [
    "# PyTorch for Deep Learning - Intro\n",
    "\n",
    "[YouTube-Video von freeCodeCamp.org](https://youtu.be/GIsg-ZUy0MY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-leave",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "[Tensor](https://pytorch.org/docs/stable/tensors) ist die zentrale Datenstruktur von PyTorch. Ein Tensor ist ein multidimensionales Array:\n",
    "* 1D: Skalar, `torch.tensor(4)`\n",
    "* 2D, 1xM: Vektor, `torch.tensor([1, 2, 3])`\n",
    "* 2D, NxM: Matrix, `torch.tensor([[1, 2], [3, 4]])`\n",
    "* 3D: multidimensionale Matrix, `torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])`\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "romantic-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atlantic-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skalar\n",
    "tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlling-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vektor\n",
    "tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polyphonic-format",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NxM-Matrix\n",
    "tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dutch-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NxMxD-Matrix\n",
    "tensor(\n",
    "    [\n",
    "        [[1, 2],\n",
    "         [3, 4]],\n",
    "        [[5, 6],\n",
    "         [7, 8]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pointed-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2],\n",
       "          [3, 4]],\n",
       "\n",
       "         [[5, 6],\n",
       "          [7, 8]]],\n",
       "\n",
       "\n",
       "        [[[1, 2],\n",
       "          [3, 4]],\n",
       "\n",
       "         [[5, 6],\n",
       "          [7, 8]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etc.\n",
    "torch.tensor([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-revision",
   "metadata": {},
   "source": [
    "## PyTorch und NumPy\n",
    "Tensoren teilen einige Features mit NumPy Arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "whole-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.Size([2, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor(4).dtype, tensor([[1, 2], [3, 4]]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-asbestos",
   "metadata": {},
   "source": [
    "Auch arithmetische Operationen sind möglich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "domestic-technique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([[2, 2], [3, 3]]) + tensor([[2, 2], [2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-healthcare",
   "metadata": {},
   "source": [
    "Tensoren können aus NumPy Arrays erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intense-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "significant-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erstellt Kopie vom Array\n",
    "tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "herbal-shirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# erstellt keine Kopie\n",
    "torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-allen",
   "metadata": {},
   "source": [
    "Tensoren können in NumPy Arrays umgewandelt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beneficial-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(4).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-september",
   "metadata": {},
   "source": [
    "## Bilder als Tensor\n",
    "Rasterbilder und Tensoren können problemlos ineinander umgewandelt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pressing-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: (256, 256, 4)\n",
      "t.shape: torch.Size([256, 256, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4f9d6da220>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = np.array(Image.open('test.png'))\n",
    "t = torch.from_numpy(img)\n",
    "print('img.shape:', img.shape)\n",
    "print('t.shape:', t.shape)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-sponsorship",
   "metadata": {},
   "source": [
    "**VORSICHT**: Bibliotheken wie matplotlib gehen davon aus, dass Bilder in der Form `Höhe x Breite x Kanäle` gespeichert sind. PyTorch arbeitet aber mit `Kanäle x Höhe x Breite`. Um also Bilder als Tensoren in PyTorch zu benutzen, müssen die Dimensionen mit `permute` vertauscht werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "average-burden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_neu = t.permute(2, 0, 1)\n",
    "t_neu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-pontiac",
   "metadata": {},
   "source": [
    "## Ein Beispiel: Lineare Regression\n",
    "\n",
    "| Region | Temp. (° c) | Niederschl. (mm) | Luftfeuchte (%) | Äpfel (t/ha) | Orangen (t/ha) |\n",
    "|--------|:-----------:|:----------------:|:---------------:|:------------:|:--------------:|\n",
    "| Kanto  |      22     |        67        |        43       |      56      |       70       |\n",
    "| Johto  |      32     |        88        |        64       |      81      |       101      |\n",
    "| Hoenn  |      30     |        134       |        58       |      119     |       133      |\n",
    "| Sinnoh |      38     |        43        |        37       |      22      |       37       |\n",
    "| Unova  |      20     |        96        |        70       |      103     |       119      |\n",
    "\n",
    "    apples = w11 * T + w12 * N + w13 * LF + b1\n",
    "\n",
    "    oranges = w21 * T + w22 * N + w32 * LF + b2\n",
    "    \n",
    "    X * W^T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mathematical-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tensor([[22, 67, 43],\n",
    "                [32, 88, 64],\n",
    "                [30, 134, 58],\n",
    "                [38, 43, 37],\n",
    "                [20, 96, 70]], dtype=torch.float32)\n",
    "\n",
    "target = tensor([[56, 70],\n",
    "                 [81, 101],\n",
    "                 [119, 133],\n",
    "                 [22, 37],\n",
    "                 [103, 119]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-outreach",
   "metadata": {},
   "source": [
    "Die Gewichte `wij` und die Bias-Terme `bi` werden zufällig initialisiert. `torch.randn` liefert einen Tensor mit standardnormalverteilten Zufallszahlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "behavioral-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-federal",
   "metadata": {},
   "source": [
    "`requires_grad` kontrolliert, ob Änderungen am Tensor aufgezeichnet werden sollen, um Berechnung des Gradienten zu ermöglichen.\n",
    "\n",
    "Damit können wir ein Modell bauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fatal-array",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9038e+01,  7.3163e-02],\n",
       "        [ 1.1122e+02,  9.6434e+00],\n",
       "        [ 1.2557e+02, -3.5306e+01],\n",
       "        [ 6.5939e+01,  1.3160e+01],\n",
       "        [ 1.1802e+02,  9.8146e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def model(x):\n",
    "    # @: Matrixmultiplikation\n",
    "    return x @ w.t() + b\n",
    "\n",
    "prediction = model(input)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-hydrogen",
   "metadata": {},
   "source": [
    "Zum Optimieren brauchen wir eine Loss-Funktion wie z. B. MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "closing-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5769.5527, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(prediction, target):\n",
    "    diff = prediction - target\n",
    "    # numel is total number of elements\n",
    "    return torch.sum(diff * diff / diff.numel())\n",
    "\n",
    "loss_initial = mse(prediction, target)\n",
    "loss_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-return",
   "metadata": {},
   "source": [
    "Da die Gewichte und Bias-Terme `requires_grad` aktiviert haben, kann PyTorch automatisch den Gradienten der Loss-Funktion bestimmen. Die einzelnen Werte werden im Attribut `.grad` des jeweiligen Tensors gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "composite-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  728.2032,  1682.9070,  1196.5468],\n",
      "        [-2520.1179, -9356.8672, -5428.0898]])\n",
      "tensor([ 23.7569, -92.5228])\n"
     ]
    }
   ],
   "source": [
    "loss_initial.backward()\n",
    "\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-mailing",
   "metadata": {},
   "source": [
    "Damit können die Gewichte und Bias-Terme gemäß dem Gradientenabstieg akutalisiert werden. `torch.no_grad()` signalisiert, dass die folgenden Operationen nicht für die nächste Gradientenberechnung aufgezeichnet werden sollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becoming-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    # Gradienten zurücksetzen (Werte werden sonst akkumuliert)\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-pantyhose",
   "metadata": {},
   "source": [
    "Mit den aktualisierten Parametern können neue Vorhersagen berechnet werden. Der Loss ist im Vergleich zu den ersten Vorhersagen bereits verringert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "selective-improvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5769.5527, grad_fn=<SumBackward0>),\n",
       " tensor(4564.3179, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(input)\n",
    "loss = mse(prediction, target)\n",
    "(loss_initial, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-advertising",
   "metadata": {},
   "source": [
    "Jetzt kann alles zusammengefügt und in z. B. 1000 Epochen wiederholt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stretch-shower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0 epochs: 17579.1953125\n",
      "Loss after 100 epochs: 323.1888427734375\n",
      "Loss after 200 epochs: 227.06295776367188\n",
      "Loss after 300 epochs: 160.89779663085938\n",
      "Loss after 400 epochs: 115.18598937988281\n",
      "Loss after 500 epochs: 83.46249389648438\n",
      "Loss after 600 epochs: 61.327552795410156\n",
      "Loss after 700 epochs: 45.783119201660156\n",
      "Loss after 800 epochs: 34.784183502197266\n",
      "Loss after 900 epochs: 26.933162689208984\n"
     ]
    }
   ],
   "source": [
    "# Modell zurücksetzen\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "for i in range(1000):\n",
    "    prediction = model(input)\n",
    "    loss = mse(prediction, target)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss after {i} epochs: {loss}')\n",
    "\n",
    "print(prediction)\n",
    "print(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
